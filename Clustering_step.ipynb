{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a79832",
   "metadata": {},
   "source": [
    "# Filtering inventory plots data using clustering procedure\n",
    "\n",
    "Goal: from dataset obtained from satelite and radar imagery (spectral and terrain characteristics and their derrivatives) we want to obtain as mush of representative data as possible.\n",
    "To do this on the data with different buffer-zone acquired by multiplying of radius of the invenotry plot, we perform clustering procedure.\n",
    "\n",
    "1) K-means\n",
    "* from the whole dataset we select only those records which correposponds to the largest cluster\n",
    "* clustering procedure is performed on the non-correlated features\n",
    "* number of clusters is selected autimatically according to the \"elbow rule\"\n",
    "* clustering is performed by each plot\n",
    "\n",
    "1.1. Attempt as it is <br>\n",
    "1.2. Feature selection step using PCA. From first two components features with explained variation under third quartile was choosen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6f0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely import affinity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04dae37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50cbb314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B09</th>\n",
       "      <th>...</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>MSAVI</th>\n",
       "      <th>NDRE</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>wetnessindex</th>\n",
       "      <th>sink</th>\n",
       "      <th>key</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.08185</td>\n",
       "      <td>0.06775</td>\n",
       "      <td>0.04215</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.16065</td>\n",
       "      <td>0.19045</td>\n",
       "      <td>0.17490</td>\n",
       "      <td>0.20245</td>\n",
       "      <td>0.06135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611610</td>\n",
       "      <td>0.260078</td>\n",
       "      <td>0.239022</td>\n",
       "      <td>0.454470</td>\n",
       "      <td>0.744224</td>\n",
       "      <td>0.034715</td>\n",
       "      <td>0.863035</td>\n",
       "      <td>0.75347</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.08360</td>\n",
       "      <td>0.06815</td>\n",
       "      <td>0.04220</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.16065</td>\n",
       "      <td>0.19045</td>\n",
       "      <td>0.17635</td>\n",
       "      <td>0.20245</td>\n",
       "      <td>0.06135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613818</td>\n",
       "      <td>0.262498</td>\n",
       "      <td>0.241437</td>\n",
       "      <td>0.457739</td>\n",
       "      <td>0.744224</td>\n",
       "      <td>0.034715</td>\n",
       "      <td>0.863035</td>\n",
       "      <td>0.75347</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      B01      B02      B03      B04     B05      B06      B07      B08  \\\n",
       "1  0.1126  0.08185  0.06775  0.04215  0.0656  0.16065  0.19045  0.17490   \n",
       "2  0.1126  0.08360  0.06815  0.04220  0.0656  0.16065  0.19045  0.17635   \n",
       "\n",
       "       B8A      B09  ...      NDVI       EVI     MSAVI      NDRE    aspect  \\\n",
       "1  0.20245  0.06135  ...  0.611610  0.260078  0.239022  0.454470  0.744224   \n",
       "2  0.20245  0.06135  ...  0.613818  0.262498  0.241437  0.457739  0.744224   \n",
       "\n",
       "      slope  wetnessindex     sink  key  class  \n",
       "1  0.034715      0.863035  0.75347    0      7  \n",
       "2  0.034715      0.863035  0.75347    0      7  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset\n",
    "\n",
    "test = pd.read_csv('test_data-х3.csv', index_col=0)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48384bd",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c350ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting correlation threshold\n",
    "correlation_threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21bcd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attaching clusters to each row according to the number of plot\n",
    "def get_cluster_pixels(data:pd.DataFrame, key: int = 1)->pd.DataFrame: \n",
    "    try:\n",
    "        attmpt = data[data.key == key]\n",
    "        attmpt_c = attmpt.drop(columns = ['key', 'class']).corr().abs() #'index',\n",
    "        #attmpt.corr().style.background_gradient(cmap=\"Blues\")\n",
    "\n",
    "        # Select upper triangle of correlation matrix\n",
    "        upper = attmpt_c.where(np.triu(np.ones(attmpt_c.shape), k=1).astype(bool))\n",
    "\n",
    "        # Find features with correlation greater than 0.95\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > correlation_threshold)]\n",
    "\n",
    "        # Drop features \n",
    "        attmpt_ = attmpt.drop(to_drop, axis=1)#, inplace=True)\n",
    "\n",
    "        #preprocessing of the data\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(attmpt_.drop(columns = ['key', 'class']))#'index',\n",
    "        scaled_data = scaler.transform(attmpt_.drop(columns = ['key', 'class']))#'index',\n",
    "\n",
    "        #from yellowbrick.cluster import KElbowVisualizer\n",
    "        model = KMeans()\n",
    "        # k is range of number of clusters.\n",
    "        visualizer = KElbowVisualizer(model, k=(1,8), timings= True)\n",
    "        visualizer.fit(scaled_data)        # Fit data to visualizer\n",
    "        plt.close()\n",
    "\n",
    "        kmeans_model = KMeans(n_clusters = visualizer.elbow_value_, random_state=100) # elbow_value_ == number of clusters\n",
    "        kmeans_model.fit(scaled_data)\n",
    "\n",
    "        attmpt[\"clusters\"] = kmeans_model.labels_\n",
    "        attmpt.clusters.value_counts().reset_index()#.duplicated(subset=['clusters'])#.iloc[0,0]\n",
    "        return attmpt\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafdd84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##selection of rows related to most abundant clusters\n",
    "\n",
    "def get_selection(attmpt:pd.DataFrame)->pd.DataFrame:\n",
    "    \n",
    "    cluster_stat = attmpt.clusters.value_counts().to_dict()\n",
    "    cluster_count = list(cluster_stat.values())\n",
    "    cluster_non_equal = cluster_count[0]>cluster_count[1]\n",
    "    if cluster_non_equal:\n",
    "        target_cluster = list(cluster_stat.keys())[0]\n",
    "        mask = attmpt.clusters == target_cluster\n",
    "        data_grol = attmpt.loc[mask]\n",
    "    else: \n",
    "        print('equal cluster')\n",
    "        data_grol = pd.DataFrame()\n",
    "    return data_grol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daeaa515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "10\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "equal cluster\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "equal cluster\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "equal cluster\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "equal cluster\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "equal cluster\n",
      "60\n",
      "61\n",
      "equal cluster\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "equal cluster\n",
      "128\n",
      "129\n",
      "130\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "equal cluster\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "equal cluster\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "equal cluster\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "equal cluster\n",
      "202\n",
      "equal cluster\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "equal cluster\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "equal cluster\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "equal cluster\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "equal cluster\n",
      "256\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "equal cluster\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "equal cluster\n",
      "285\n",
      "286\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "clustered_df = pd.DataFrame()\n",
    "attmpt = pd.DataFrame()\n",
    "\n",
    "for item in test.key.unique():\n",
    "    try:\n",
    "        attmpt = get_cluster_pixels(test, key=item)\n",
    "        attmpt = get_selection(attmpt)\n",
    "        clustered_df = pd.concat([clustered_df, attmpt])\n",
    "        print(item) # mute at the final stage, needed for the check\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5f3d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows kept from initial dataset is equal to 43 %\n"
     ]
    }
   ],
   "source": [
    "print('Rows kept from initial dataset is equal to', round(len(clustered_df)/len(test)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8ad6e",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2079392",
   "metadata": {},
   "source": [
    "THIS SCRIPT NEEDS TO BECOME PRETTIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b751bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f48a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_pixels_PCA(data:pd.DataFrame, key: int = 1)->pd.DataFrame: \n",
    "    try:\n",
    "        #subsetting\n",
    "        attmpt_pca_step = data[data.key == key]\n",
    "        #abjusting columns\n",
    "        cols_to_drop = ['key', 'class'] #'index',\n",
    "        attempt_pca = attmpt_pca_step.drop(columns = cols_to_drop)\n",
    "        \n",
    "        #getting values and scalling them\n",
    "        X = attempt_pca.values\n",
    "        scaler_pca = StandardScaler()\n",
    "        scaler_pca.fit(X)\n",
    "        X_scaled = scaler_pca.transform(X)\n",
    "        \n",
    "        #performing of principal component analysis\n",
    "        pca = PCA(n_components=20, random_state=2020)\n",
    "        pca.fit(X_scaled)\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        \n",
    "        #selecting columns for clustering\n",
    "        \n",
    "        #first component\n",
    "        stat_eigen = pd.DataFrame(pca.components_, \n",
    "                                  columns=attempt_pca.columns).T.loc[:, 0].abs().quantile(0.75)#.mean()#\n",
    "        pca_results = pd.DataFrame(pca.components_,columns=attempt_pca.columns).T#.loc[mean_eqigen]\n",
    "        mask_pca = pca_results.loc[:, 0].abs() > stat_eigen #selecting components with loads above third quartile \n",
    "        columns_for_clustering = pca_results.loc[mask_pca].index.tolist()\n",
    "        \n",
    "        #second component\n",
    "        stat_eigen = pd.DataFrame(pca.components_,\n",
    "                                  columns=attempt_pca.columns).T.loc[:, 1].abs().quantile(0.75)#.mean()#\n",
    "        pca_results = pd.DataFrame(pca.components_,columns=attempt_pca.columns).T#.loc[mean_eqigen]\n",
    "        mask_pca = pca_results.loc[:, 1].abs() > stat_eigen #selecting components with loads above third quartile\n",
    "        second_component = pca_results.loc[mask_pca].index.tolist()\n",
    "        \n",
    "        #final list of columns for clustering\n",
    "        columns_for_clustering = columns_for_clustering+second_component\n",
    "        \n",
    "        # filtering subset by columns from previous step\n",
    "        data_for_clustering = attempt_pca.loc[:, columns_for_clustering]\n",
    "        \n",
    "        #BACK TO K-MEANS\n",
    "         \n",
    "        #preprocessing of the data\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data_for_clustering)#'index',\n",
    "        scaled_data = scaler.transform(data_for_clustering)#'index',\n",
    "\n",
    "        #from yellowbrick.cluster import KElbowVisualizer\n",
    "        model = KMeans()\n",
    "        # k is range of number of clusters.\n",
    "        visualizer = KElbowVisualizer(model, k=(1,8), timings= True)\n",
    "        visualizer.fit(scaled_data)        # Fit data to visualizer\n",
    "        plt.close()\n",
    "\n",
    "        kmeans_model = KMeans(n_clusters = visualizer.elbow_value_, random_state=100) # elbow_value_ == number of clusters\n",
    "        kmeans_model.fit(scaled_data)\n",
    "\n",
    "        attmpt_pca_step[\"clusters\"] = kmeans_model.labels_\n",
    "        #attmpt.clusters.value_counts().reset_index()#.duplicated(subset=['clusters'])#.iloc[0,0]\n",
    "        return attmpt_pca_step\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1dbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##selection of rows related to most abundant clusters\n",
    "\n",
    "def get_selection_PCA(attmpt_pca_step:pd.DataFrame)->pd.DataFrame:\n",
    "    \n",
    "    cluster_stat = attmpt_pca_step.clusters.value_counts().to_dict()\n",
    "    cluster_count = list(cluster_stat.values())\n",
    "    cluster_non_equal = cluster_count[0]>cluster_count[1]\n",
    "    if cluster_non_equal:\n",
    "        target_cluster = list(cluster_stat.keys())[0]\n",
    "        mask = attmpt_pca_step.clusters == target_cluster\n",
    "        data_grol = attmpt_pca_step.loc[mask]\n",
    "    else: \n",
    "        print('equal cluster')\n",
    "        data_grol = pd.DataFrame()\n",
    "    return data_grol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9deaaa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "equal cluster\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "equal cluster\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "equal cluster\n",
      "50\n",
      "equal cluster\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "equal cluster\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "equal cluster\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "equal cluster\n",
      "84\n",
      "equal cluster\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "equal cluster\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "equal cluster\n",
      "114\n",
      "equal cluster\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "equal cluster\n",
      "127\n",
      "128\n",
      "129\n",
      "equal cluster\n",
      "130\n",
      "132\n",
      "133\n",
      "equal cluster\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "equal cluster\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "equal cluster\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "equal cluster\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "equal cluster\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "equal cluster\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "equal cluster\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "270\n",
      "274\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "equal cluster\n",
      "285\n",
      "286\n"
     ]
    }
   ],
   "source": [
    "clustered_df_PCA = pd.DataFrame()\n",
    "attmpt = pd.DataFrame()\n",
    "\n",
    "for item in test.key.unique():\n",
    "    try:\n",
    "        attmpt = get_cluster_pixels_PCA(test, key=item)\n",
    "        attmpt = get_selection_PCA(attmpt)\n",
    "        clustered_df_PCA = pd.concat([clustered_df_PCA, attmpt])\n",
    "        print(item) # mute at the final stage, needed for the check\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d114e535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows kept from initial dataset is equal to 45 %\n"
     ]
    }
   ],
   "source": [
    "print('Rows kept from initial dataset is equal to', round(len(clustered_df_PCA)/len(test)*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06dcd3",
   "metadata": {},
   "source": [
    "🤸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
